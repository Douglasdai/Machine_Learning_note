{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "HW7的任務是模型壓縮 - Neural Network Compression。\r\n",
    "\r\n",
    "Compression有很多種門派，在這裡我們會介紹上課出現過的其中四種，分別是:\r\n",
    "\r\n",
    "知識蒸餾 Knowledge Distillation\r\n",
    "網路剪枝 Network Pruning\r\n",
    "用少量參數來做CNN Architecture Design\r\n",
    "參數量化 Weight Quantization\r\n",
    "在這個notebook中我們會介紹MobileNet v1的Architecture Design。\r\n",
    "\"\"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Architecture Design\r\n",
    "\r\n",
    "## Depthwise & Pointwise Convolution\r\n",
    "![](https://i.imgur.com/FBgcA0s.png)\r\n",
    "> 藍色為上下層Channel的關係，綠色則為該Receptive Field的擴張。\r\n",
    "> (圖片引用自arxiv:1810.04231)\r\n",
    "\r\n",
    "(a) 就是一般的Convolution Layer，所以他的Weight連接方式會跟Fully Connected一樣，只差在原本在FC是用數字相乘後相加，Convolution Layer是圖片卷積後相加。\r\n",
    "\r\n",
    "(b) DW(Depthwise Convolution Layer)你可以想像成一張feature map各自過**一個filter**處理後，再用PW(Pointwise Convolution Layer)把所有feature map的單個pixel資訊合在一起(就是1個pixel的Fully Connected Layer)。\r\n",
    "\r\n",
    "(c) GC(Group Convolution Layer)就是把feature map分組，讓他們自己過Convolution Layer後再重新Concat起來。算是一般的Convolution和Depthwise Convolution的折衷版。**所以說，Group Convolution的Group=Input Feautures數就會是Depthwise Convolution(因為每個Channel都各自獨立)，Group=1就會是一般的Convolution(因為就等於沒有Group)。**\r\n",
    "\r\n",
    "<img src=\"https://i.imgur.com/Hqhg0Q9.png\" width=\"500px\">\r\n",
    "\r\n",
    "\r\n",
    "## 實作細節\r\n",
    "```python\r\n",
    "# 一般的Convolution, weight大小 = in_chs * out_chs * kernel_size^2\r\n",
    "nn.Conv2d(in_chs, out_chs, kernel_size, stride, padding)\r\n",
    "\r\n",
    "# Group Convolution, Group數目可以自行控制，表示要分成幾群。其中in_chs和out_chs必須要可以被groups整除。(不然沒辦法分群。)\r\n",
    "nn.Conv2d(in_chs, out_chs, kernel_size, stride, padding, groups=groups)\r\n",
    "\r\n",
    "# Depthwise Convolution, 輸入chs=輸出chs=Groups數目, weight大小 = in_chs * kernel_size^2\r\n",
    "nn.Conv2d(in_chs, out_chs=in_chs, kernel_size, stride, padding, groups=in_chs)\r\n",
    "\r\n",
    "# Pointwise Convolution, 也就是1 by 1 convolution, weight大小 = in_chs * out_chs\r\n",
    "nn.Conv2d(in_chs, out_chs, 1)\r\n",
    "```\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#Architecture Design\r\n",
    "#model\r\n",
    "import torch.nn as nn  \r\n",
    "import torch.nn.functional as F\r\n",
    "import torch \r\n",
    "import os \r\n",
    "import numpy as np \r\n",
    "import cv2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class StudentNet(nn.Module):\r\n",
    "    '''\r\n",
    "      在這個Net裡面，我們會使用Depthwise & Pointwise Convolution Layer來疊model。\r\n",
    "      你會發現，將原本的Convolution Layer換成Dw & Pw後，Accuracy通常不會降很多。\r\n",
    "\r\n",
    "      另外，取名為StudentNet是因為這個Model等會要做Knowledge Distillation。\r\n",
    "    '''\r\n",
    "    def __init__(self,base = 16,width_mult = 1):\r\n",
    "        super(StudentNet,self).__init__()\r\n",
    "        multiplier = [1,2,4,8,16,16,16,16]\r\n",
    "        bandwidth =[base*m for m in multiplier]\r\n",
    "\r\n",
    "        for i in range(3,7):\r\n",
    "            bandwidth[i] = int(bandwidth[i]* width_mult)\r\n",
    "        \r\n",
    "        self.cnn = nn.Sequential(\r\n",
    "            nn.Sequential(\r\n",
    "            nn.Conv2d(3,bandwidth[0],3,1,1),\r\n",
    "            nn.BatchNorm2d(bandwidth[0]),\r\n",
    "            nn.ReLU6(),\r\n",
    "            nn.MaxPool2d(2,2,0),\r\n",
    "            ),\r\n",
    "            nn.Sequential(\r\n",
    "                nn.Conv2d(bandwidth[0],bandwidth[0],3,1,1),\r\n",
    "                nn.BatchNorm2d(bandwidth[0]),\r\n",
    "                nn.ReLU6(),\r\n",
    "                nn.Conv2d(bandwidth[0],bandwidth[1],1),\r\n",
    "                nn.MaxPool2d(2,2,0),\r\n",
    "            ),\r\n",
    "            nn.Sequential(\r\n",
    "                nn.Conv2d(bandwidth[1], bandwidth[1], 3, 1, 1, groups=bandwidth[1]),\r\n",
    "                nn.BatchNorm2d(bandwidth[1]),\r\n",
    "                nn.ReLU6(),\r\n",
    "                nn.Conv2d(bandwidth[1], bandwidth[2], 1),\r\n",
    "                nn.MaxPool2d(2, 2, 0),\r\n",
    "            ),\r\n",
    "            nn.Sequential(\r\n",
    "                nn.Conv2d(bandwidth[2], bandwidth[2], 3, 1, 1, groups=bandwidth[2]),\r\n",
    "                nn.BatchNorm2d(bandwidth[2]),\r\n",
    "                nn.ReLU6(),\r\n",
    "                nn.Conv2d(bandwidth[2], bandwidth[3], 1),\r\n",
    "                nn.MaxPool2d(2, 2, 0),\r\n",
    "            ),\r\n",
    "            #bandwidth 16\r\n",
    "            nn.Sequential(\r\n",
    "                nn.Conv2d(bandwidth[3], bandwidth[3], 3, 1, 1, groups=bandwidth[3]),\r\n",
    "                nn.BatchNorm2d(bandwidth[3]),\r\n",
    "                nn.ReLU6(),\r\n",
    "                nn.Conv2d(bandwidth[3], bandwidth[4], 1),\r\n",
    "            ),\r\n",
    "            nn.Sequential(\r\n",
    "                nn.Conv2d(bandwidth[4], bandwidth[4], 3, 1, 1, groups=bandwidth[4]),\r\n",
    "                nn.BatchNorm2d(bandwidth[4]),\r\n",
    "                nn.ReLU6(),\r\n",
    "                nn.Conv2d(bandwidth[4], bandwidth[5], 1),\r\n",
    "            ),\r\n",
    "            nn.Sequential(\r\n",
    "                nn.Conv2d(bandwidth[5], bandwidth[5], 3, 1, 1, groups=bandwidth[5]),\r\n",
    "                nn.BatchNorm2d(bandwidth[5]),\r\n",
    "                nn.ReLU6(),\r\n",
    "                nn.Conv2d(bandwidth[5], bandwidth[6], 1),\r\n",
    "            ),\r\n",
    "            nn.Sequential(\r\n",
    "                nn.Conv2d(bandwidth[6], bandwidth[6], 3, 1, 1, groups=bandwidth[6]),\r\n",
    "                nn.BatchNorm2d(bandwidth[6]),\r\n",
    "                nn.ReLU6(),\r\n",
    "                nn.Conv2d(bandwidth[6], bandwidth[7], 1),\r\n",
    "            ),\r\n",
    "            # 這邊我們採用Global Average Pooling。\r\n",
    "            # 如果輸入圖片大小不一樣的話，就會因為Global Average Pooling壓成一樣的形狀，這樣子接下來做FC就不會對不起來。\r\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\r\n",
    "        )\r\n",
    "        self.fc = nn.Sequential(\r\n",
    "            nn.Linear(bandwidth[7],11),\r\n",
    "        )\r\n",
    "    def forward(self, x):\r\n",
    "        out = self.cnn(x)\r\n",
    "        out = out.view(out.size()[0], -1)\r\n",
    "        return self.fc(out)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def readfile(path,label):\r\n",
    "    image_dir = sorted(os.listdir(path))\r\n",
    "    x = np.zeros((len(image_dir),128,128,3),dtype=np.uint8)\r\n",
    "    y = np.zeros((len(image_dir)),dtype=np.uint8)\r\n",
    "    for i,file in enumerate(image_dir):\r\n",
    "        img = cv2.imread(os.path.join(path,file))\r\n",
    "        x[i,:,:] = cv2.resize(img,(128,128))\r\n",
    "        if label:\r\n",
    "            y[i] = int(file.split(\"_\")[0])\r\n",
    "    if label:\r\n",
    "        return x,y \r\n",
    "    else:\r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "workspace_dir = '../HW_3/data'\r\n",
    "print(\"reading data...\")\r\n",
    "train_x,train_y = readfile(os.path.join(workspace_dir,\"training\"),True)\r\n",
    "print(\"Size of training data  = {}\".format(len(train_x)))\r\n",
    "val_x,val_y = readfile(os.path.join(workspace_dir,\"validation\"),True)\r\n",
    "print(\"Size of validation data  = {}\".format(len(val_x)))\r\n",
    "test_x= readfile(os.path.join(workspace_dir,\"testing\"),False)\r\n",
    "print(\"Size of Testing data = {}\".format(len(test_x)))\r\n",
    "print(\"Over\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# training 時做 data augmentation\r\n",
    "import torchvision.transforms as transforms\r\n",
    "from torch.utils.data import DataLoader,Dataset\r\n",
    "train_transform = transforms.Compose([\r\n",
    "    transforms.ToPILImage(),\r\n",
    "    transforms.RandomHorizontalFlip(), # 隨機將圖片水平翻轉\r\n",
    "    transforms.RandomRotation(15), # 隨機旋轉圖片\r\n",
    "    transforms.ToTensor(), # 將圖片轉成 Tensor，並把數值 normalize 到 [0,1] (data normalization)\r\n",
    "])\r\n",
    "# testing 時不需做 data augmentation\r\n",
    "test_transform = transforms.Compose([\r\n",
    "    transforms.ToPILImage(),                                    \r\n",
    "    transforms.ToTensor(),\r\n",
    "])\r\n",
    "class ImgDataset(Dataset):\r\n",
    "    def __init__(self, x, y=None, transform=None):\r\n",
    "        self.x = x\r\n",
    "        # label is required to be a LongTensor\r\n",
    "        self.y = y\r\n",
    "        if y is not None:\r\n",
    "            self.y = torch.LongTensor(y)\r\n",
    "        self.transform = transform\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.x)\r\n",
    "    def __getitem__(self, index):\r\n",
    "        X = self.x[index]\r\n",
    "        if self.transform is not None:\r\n",
    "            X = self.transform(X)\r\n",
    "        if self.y is not None:\r\n",
    "            Y = self.y[index]\r\n",
    "            return X, Y\r\n",
    "        else:\r\n",
    "            return X"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch_size=4\r\n",
    "train_set = ImgDataset(train_x,train_y,train_transform)\r\n",
    "val_set = ImgDataset(val_x,val_y,test_transform)\r\n",
    "train_loader = DataLoader(train_set,batch_size = batch_size,shuffle=True)\r\n",
    "val_loader = DataLoader(val_set,batch_size=batch_size,shuffle=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "model = StudentNet().to(device)\r\n",
    "cirection = nn.CrossEntropyLoss()\r\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#train\r\n",
    "#train\r\n",
    "# model.train()\r\n",
    "import time\r\n",
    "epochs = 30\r\n",
    "for epoch in range(epochs):\r\n",
    "    epoch_start_time = time.time()\r\n",
    "    train_acc =0.0\r\n",
    "    val_acc =0.0\r\n",
    "    train_loss = 0.0\r\n",
    "    val_loss =0.0\r\n",
    "    model.train()\r\n",
    "    for i,data in enumerate(train_loader):\r\n",
    "        optimizer.zero_grad()\r\n",
    "        x,y = data[0].to(device),data[1].to(device)\r\n",
    "        # print(x.shape)\r\n",
    "        y_pred = model(x)\r\n",
    "        loss = cirection(y_pred,y.long())\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        train_acc +=np.sum(np.argmax(y_pred.cpu().data.numpy(),axis=1)== y.cpu().numpy())\r\n",
    "        train_loss +=loss.item()\r\n",
    "    model.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "        for i,data in enumerate(val_loader):\r\n",
    "            valx ,valy = data[0].to(device),data[1].to(device)\r\n",
    "            val_pred = model(valx)\r\n",
    "            batch_loss = cirection(val_pred,valy.long())\r\n",
    "            val_acc +=np.sum(np.argmax(val_pred.cpu().data.numpy(),axis=1)== valy.cpu().numpy())\r\n",
    "            val_loss +=batch_loss.item()\r\n",
    "\r\n",
    "        print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\r\n",
    "            (epoch + 1, epochs, time.time()-epoch_start_time, \\\r\n",
    "             train_acc/train_set.__len__(), train_loss/train_set.__len__(), val_acc/val_set.__len__(), val_loss/val_set.__len__()))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#train and val 共同训练\r\n",
    "train_val_x = np.concatenate((train_x,val_x),axis=0)\r\n",
    "train_val_y = np.concatenate((train_y,val_y),axis=0)\r\n",
    "train_val_set =ImgDataset(train_val_x,train_val_y,train_transform)\r\n",
    "train_val_loader = DataLoader(train_val_set,batch_size=batch_size,shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_best = StudentNet.to(device)\r\n",
    "epochs = 30\r\n",
    "for epoch in range(epochs):\r\n",
    "    epoch_start_time = time.time()\r\n",
    "    train_acc =0.0\r\n",
    "    val_acc =0.0\r\n",
    "    train_loss = 0.0\r\n",
    "    val_loss =0.0\r\n",
    "    model.train()\r\n",
    "    for i,data in enumerate(train_loader):\r\n",
    "        optimizer.zero_grad()\r\n",
    "        x,y = data[0].to(device),data[1].to(device)\r\n",
    "        y_pred = model_best(x)\r\n",
    "        loss = cirection(y_pred,y.long())\r\n",
    "        train_loss +=loss\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        train_acc +=np.sum(np.argmax(y_pred.cpu().data.numpy(),axis=1)== y.cpu().numpy())\r\n",
    "    print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f '\r\n",
    "    (epoch + 1, epochs, time.time()-epoch_start_time, \\\r\n",
    "        train_acc/train_set.__len__(), train_loss/train_set.__len__())\r\n",
    "\r\n",
    "torch.save('studentnet.pth')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit"
  },
  "interpreter": {
   "hash": "0843aa2147bb7b68e1331c060614b1ebfeaba0f0db744f4b489daeb337a1f0b2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}