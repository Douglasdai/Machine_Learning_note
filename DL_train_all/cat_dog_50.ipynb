{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import cv2\n",
    "import torch.nn as nn \n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make data\n",
    "REBUILD_DATA = False\n",
    "\n",
    "class CatsVSDogs():\n",
    "    \n",
    "    # Size of the image\n",
    "    IMG_SIZE = 50\n",
    "    \n",
    "    # Directory location\n",
    "    CATS = 'D:/ML_data_sql/PetImages/Cat/'\n",
    "    DOGS = 'D:/ML_data_sql/PetImages/Dog/'\n",
    "    \n",
    "    # Labels for cats and dogs\n",
    "    LABELS = {CATS:0, DOGS:1}\n",
    "    \n",
    "    # Initializing variables\n",
    "    training_data = []\n",
    "    catcount = 0\n",
    "    dogcount = 0\n",
    "    \n",
    "    def make_training_data(self):\n",
    "        for label in self.LABELS:\n",
    "            \n",
    "            # Looping through each pictures\n",
    "            for f in tqdm(os.listdir(label)):\n",
    "                \n",
    "                try:\n",
    "                    path = os.path.join(label, f)\n",
    "\n",
    "                    # Reading images and converting to grayscale\n",
    "                    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "\n",
    "                    # Resizing images\n",
    "                    img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
    "\n",
    "                    # Getting the training data\n",
    "                    self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])\n",
    "\n",
    "                    # Checking distribution of data\n",
    "                    if label == self.CATS:\n",
    "                        self.catcount += 1\n",
    "                    elif label == self.DOGS:\n",
    "                        self.dogcount += 1\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    pass\n",
    "\n",
    "            np.random.shuffle(self.training_data)\n",
    "            np.save(\"training_data_color.npy\", self.training_data)\n",
    "            print(\"Cates: \", self.catcount)\n",
    "            print(\"Dogs: \", self.dogcount)\n",
    "            \n",
    "if REBUILD_DATA:\n",
    "    catsvdogs = CatsVSDogs()\n",
    "    catsvdogs.make_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load(\"training_data.npy\", allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#展示一下图片\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(training_data[1][0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7:3 分别训练 先标准化 并load data\n",
    "# Getting the features\n",
    "X = torch.Tensor([i[0] for i in training_data]).view(-1, 50, 50)\n",
    "# Scaling the features\n",
    "X = X/255.0\n",
    "# Getting the target\n",
    "y = torch.Tensor([i[1] for i in training_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test\n",
    "val = int(len(X)*0.3)\n",
    "train_X = X[:-val]\n",
    "test_X = X[-val:]\n",
    "train_y = y[:-val]\n",
    "test_y = y[-val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "class Classfication(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classfication,self).__init__()\n",
    "        #tensor 50* 50*1\n",
    "        self.conv1 = nn.Conv2d(1,64,3)\n",
    "        self.conv2 = nn.Conv2d(64,128,3)\n",
    "        self.conv3 = nn.Conv2d(128,64,5,1,1)\n",
    "        self.conv4 = nn.Conv2d(64,32,3)\n",
    "        self.fc1 = nn.Linear(32*4*4,128)\n",
    "        self.fc2 = nn.Linear(128,2)\n",
    "    def forward(self,x):\n",
    "        in_size = x.size(0)\n",
    "        #50\n",
    "        out = self.conv1(x) #1*48*48\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out,2)    # 1*24*24\n",
    "        out = self.conv2(out)   # 1*22 *22\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out,2)   # 1*11*11\n",
    "        #(H-K+2*P)/S+1, (11-5+2) +1 ==9\n",
    "        out = self.conv3(out)   # 1*9*9\n",
    "        out = F.relu(out)   # 7*7\n",
    "        out = self.conv4(out)\n",
    "        # print(out.shape)\n",
    "        out = F.max_pool2d(out,2,padding=1)\n",
    "        out = out.view(in_size,-1)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = F.softmax(out,dim=1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#settings \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "# print(device)\n",
    "model = Classfication().to(device)\n",
    "cirection = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "# Number of Epochs\n",
    "EPOCHS = 50\n",
    "# Model Training\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in tqdm(range(0, len(train_X), BATCH_SIZE)):\n",
    "        batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50,50).to(device)\n",
    "        batch_y = train_y[i:i+BATCH_SIZE].to(device)\n",
    "        model.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = cirection(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(test_X))):\n",
    "        real_class = torch.argmax(test_y[i])\n",
    "        net_out = model(test_X[i].view(-1,1,50,50).to(device))\n",
    "        predicted_class = torch.argmax(net_out)\n",
    "        if predicted_class == real_class:\n",
    "            correct += 1\n",
    "        total +=1\n",
    "print(\"Accuracy: \", round(correct/total, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'cat_dog_52.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0843aa2147bb7b68e1331c060614b1ebfeaba0f0db744f4b489daeb337a1f0b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
