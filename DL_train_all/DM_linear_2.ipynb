{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) 5\n",
      "(10000, 28, 28) (10000,) 7\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "(X_train,Y_train),(X_test,Y_test) = mnist.load_data()\n",
    "#X 为图片 ，2维  y  为 label \n",
    "print(X_train.shape,Y_train.shape,Y_train[0])\n",
    "print(X_test.shape,Y_test.shape,Y_test[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0].reshape(28,28), cmap='gray');\n",
    "# 关闭坐标轴\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "# training 時做 data augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(), # 隨機將圖片水平翻轉\n",
    "    transforms.RandomRotation(15), # 隨機旋轉圖片\n",
    "    transforms.ToTensor(), # 將圖片轉成 Tensor，並把數值 normalize 到 [0,1] (data normalization)\n",
    "])\n",
    "# testing 時不需做 data augmentation\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),                                    \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, x, y=None, transform=None):\n",
    "        self.x = x\n",
    "        # label is required to be a LongTensor\n",
    "        self.y = y\n",
    "        if y is not None:\n",
    "            self.y = torch.LongTensor(y)\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, index):\n",
    "        X = self.x[index]\n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "        if self.y is not None:\n",
    "            Y = self.y[index]\n",
    "            return X, Y\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "train_set = ImgDataset(X_train,Y_train,test_transform)\n",
    "val_set = ImgDataset(X_test,Y_test,test_transform)\n",
    "train_loader = DataLoader(train_set,batch_size = batch_size,shuffle=True)\n",
    "val_loader = DataLoader(val_set,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "        # input 維度 [64,1, 28, 28]\n",
    "        # self.cnn = nn.Sequential(\n",
    "        #     nn.Conv2d(1, 16, 3, 1, 1),  # [64, 28, 28]\n",
    "        #     nn.BatchNorm2d(16),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(2, 2, 0),      # [64, 14, 14]\n",
    "\n",
    "        #     nn.Conv2d(16, 32, 3, 1, 1), # [128, 14, 14]\n",
    "        #     nn.BatchNorm2d(32),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(2, 2, 0),      # [128, 7, 7]\n",
    "            \n",
    "        #     nn.Conv2d(32, 64, 3, 1, 1), # [512, 7, 7]\n",
    "        #     nn.BatchNorm2d(64),\n",
    "        #     nn.ReLU(),\n",
    "        # )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(784,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #out = self.cnn(x)\n",
    "        x = x.view(-1, 784)\n",
    "        #print(x.shape)\n",
    "        out = self.fc(x)\n",
    "        return out\n",
    "\n",
    "class LinearR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearR, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(784,512),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #out = self.cnn(x)\n",
    "        x = x.view(-1, 784)\n",
    "        #print(x.shape)\n",
    "        out = self.fc(x)\n",
    "        return out\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "        # input 維度 [64,1, 28, 28]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, 1, 1),  # [64, 28, 28]\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [64, 14, 14]\n",
    "\n",
    "            nn.Conv2d(16, 32, 3, 1, 1), # [128, 14, 14]\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [128, 7, 7]\n",
    "            \n",
    "            nn.Conv2d(32, 64, 3, 1, 1), # [512, 7, 7]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(784,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        x = x.view(-1, 784)\n",
    "        #print(x.shape)\n",
    "        out = self.fc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "# print(device)\n",
    "model = Classifier().to(device)\n",
    "cirection = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/020] 5.65 sec(s) Train Acc: 0.897733 Loss: 0.001533 | Val Acc: 0.942300 loss: 0.000783\n",
      "[002/020] 5.90 sec(s) Train Acc: 0.952100 Loss: 0.000648 | Val Acc: 0.960100 loss: 0.000527\n",
      "[003/020] 6.34 sec(s) Train Acc: 0.967533 Loss: 0.000440 | Val Acc: 0.966900 loss: 0.000419\n",
      "[004/020] 5.50 sec(s) Train Acc: 0.975350 Loss: 0.000332 | Val Acc: 0.971900 loss: 0.000364\n",
      "[005/020] 5.29 sec(s) Train Acc: 0.981050 Loss: 0.000255 | Val Acc: 0.976500 loss: 0.000312\n",
      "[006/020] 5.28 sec(s) Train Acc: 0.985133 Loss: 0.000204 | Val Acc: 0.978000 loss: 0.000285\n",
      "[007/020] 5.74 sec(s) Train Acc: 0.988800 Loss: 0.000161 | Val Acc: 0.978000 loss: 0.000286\n",
      "[008/020] 5.38 sec(s) Train Acc: 0.990683 Loss: 0.000129 | Val Acc: 0.978500 loss: 0.000259\n",
      "[009/020] 5.28 sec(s) Train Acc: 0.992617 Loss: 0.000109 | Val Acc: 0.979100 loss: 0.000257\n",
      "[010/020] 5.43 sec(s) Train Acc: 0.994900 Loss: 0.000084 | Val Acc: 0.981300 loss: 0.000233\n",
      "[011/020] 5.28 sec(s) Train Acc: 0.996317 Loss: 0.000067 | Val Acc: 0.979800 loss: 0.000265\n",
      "[012/020] 5.31 sec(s) Train Acc: 0.997117 Loss: 0.000055 | Val Acc: 0.981800 loss: 0.000243\n",
      "[013/020] 5.37 sec(s) Train Acc: 0.997717 Loss: 0.000045 | Val Acc: 0.980700 loss: 0.000251\n",
      "[014/020] 5.32 sec(s) Train Acc: 0.998333 Loss: 0.000036 | Val Acc: 0.980500 loss: 0.000257\n",
      "[015/020] 5.28 sec(s) Train Acc: 0.998883 Loss: 0.000029 | Val Acc: 0.980700 loss: 0.000254\n",
      "[016/020] 5.28 sec(s) Train Acc: 0.999217 Loss: 0.000023 | Val Acc: 0.981800 loss: 0.000255\n",
      "[017/020] 5.54 sec(s) Train Acc: 0.999600 Loss: 0.000017 | Val Acc: 0.981500 loss: 0.000253\n",
      "[018/020] 6.43 sec(s) Train Acc: 0.999350 Loss: 0.000019 | Val Acc: 0.980100 loss: 0.000277\n",
      "[019/020] 6.21 sec(s) Train Acc: 0.999817 Loss: 0.000011 | Val Acc: 0.980400 loss: 0.000264\n",
      "[020/020] 5.49 sec(s) Train Acc: 0.999950 Loss: 0.000008 | Val Acc: 0.982500 loss: 0.000255\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    train_acc =0.0\n",
    "    val_acc =0.0\n",
    "    train_loss = 0.0\n",
    "    val_loss =0.0\n",
    "    model.train()\n",
    "    for i,data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x,y = data[0].to(device),data[1].to(device)\n",
    "        #print(x.shape)\n",
    "        y_pred = model(x)\n",
    "        loss = cirection(y_pred,y.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_acc +=np.sum(np.argmax(y_pred.cpu().data.numpy(),axis=1)== y.cpu().numpy())\n",
    "        train_loss +=loss.item()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(val_loader):\n",
    "            valx ,valy = data[0].to(device),data[1].to(device)\n",
    "            val_pred = model(valx)\n",
    "            batch_loss = cirection(val_pred,valy.long())\n",
    "            val_acc +=np.sum(np.argmax(val_pred.cpu().data.numpy(),axis=1)== valy.cpu().numpy())\n",
    "            val_loss +=batch_loss.item()\n",
    "\n",
    "        print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\n",
    "            (epoch + 1, epochs, time.time()-epoch_start_time, \\\n",
    "             train_acc/train_set.__len__(), train_loss/train_set.__len__(), val_acc/val_set.__len__(), val_loss/val_set.__len__()))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0843aa2147bb7b68e1331c060614b1ebfeaba0f0db744f4b489daeb337a1f0b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
