{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n数据集介绍：\\n  该数据集包含1958年至1970年期间在芝加哥大学比林斯医院进行的一项研究中的病例。\\n   1958年至1970年期间在芝加哥大学比林斯医院进行的一项研究的案例。\\n   该研究是在1958年至1970年间在芝加哥大学比林斯医院进行的，研究对象是接受过乳腺癌手术的病人的生存情况。\\n   癌症的病人的生存率。\\n   \\n1. 手术时病人的年龄（数字）。\\n2. 病人手z术的年份（年份-1900，数字）。\\n3. 检测到的腋窝阳性结节的数量（数字\\n4. 生存状态（类属性\\n        1 = 患者存活5年或更长时间\\n        2 = 患者在5年内死亡\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dtplot\n",
    "from math import log\n",
    "import operator\n",
    "from collections import Counter\n",
    "pre_pruning = False\n",
    "post_pruning = False\n",
    "#使用的是 UCI-herbeman  data 数据集\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集介绍：\n",
    "  该数据集包含1958年至1970年期间在芝加哥大学比林斯医院进行的一项研究中的病例。\n",
    "   1958年至1970年期间在芝加哥大学比林斯医院进行的一项研究的案例。\n",
    "   该研究是在1958年至1970年间在芝加哥大学比林斯医院进行的，研究对象是接受过乳腺癌手术的病人的生存情况。\n",
    "   癌症的病人的生存率。\n",
    "   \n",
    "1. 手术时病人的年龄（数字）。\n",
    "2. 病人手z术的年份（年份-1900，数字）。\n",
    "3. 检测到的腋窝阳性结节的数量（数字\n",
    "4. 生存状态（类属性\n",
    "        1 = 患者存活5年或更长时间\n",
    "        2 = 患者在5年内死亡\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(filename):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    fr = open(filename, 'r',encoding='utf-8')\n",
    "    all_lines = fr.readlines()  # list形式,每行为1个str\n",
    "    # print all_lines\n",
    "    labels = ['年龄','手术时间','腋窝结节数量','死亡时间','种类']\n",
    "    labelCounts = {}\n",
    "    dataset = []\n",
    "    for line in all_lines[0:]:\n",
    "        line = line.strip().split(',')  # 以逗号为分割符拆分列表\n",
    "        dataset.append(line)\n",
    "    return dataset, labels\n",
    "\n",
    "def read_testset(testfile):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    fr = open(testfile, 'r',encoding='utf-8')\n",
    "    all_lines = fr.readlines()\n",
    "    testset = []\n",
    "    for line in all_lines[0:]:\n",
    "        line = line.strip().split(',')  # 以逗号为分割符拆分列表\n",
    "        testset.append(line)\n",
    "    return testset\n",
    "\n",
    "# 计算信息熵\n",
    "def cal_entropy(dataset):\n",
    "    numEntries = len(dataset)\n",
    "    labelCounts = {}\n",
    "    # 给所有可能分类创建字典\n",
    "    for featVec in dataset:\n",
    "        currentlabel = featVec[-1]\n",
    "        if currentlabel not in labelCounts.keys():\n",
    "            labelCounts[currentlabel] = 0\n",
    "        labelCounts[currentlabel] += 1\n",
    "    Ent = 0.0\n",
    "    for key in labelCounts:\n",
    "        p = float(labelCounts[key]) / numEntries\n",
    "        Ent = Ent - p * log(p, 2)  # 以2为底求对数\n",
    "    return Ent\n",
    "\n",
    "\n",
    "# 划分数据集\n",
    "def splitdataset(dataset, axis, value):\n",
    "    retdataset = []  # 创建返回的数据集列表\n",
    "    for featVec in dataset:  # 抽取符合划分特征的值\n",
    "        if featVec[axis] == value:\n",
    "            reducedfeatVec = featVec[:axis]  # 去掉axis特征\n",
    "            reducedfeatVec.extend(featVec[axis + 1:])  # 将符合条件的特征添加到返回的数据集列表\n",
    "            retdataset.append(reducedfeatVec)\n",
    "    return retdataset\n",
    "\n",
    "\n",
    "'''\n",
    "选择最好的数据集划分方式\n",
    "ID3算法:以信息增益为准则选择划分属性\n",
    "C4.5算法：使用“增益率”来选择划分属性\n",
    "'''\n",
    "# ID3算法\n",
    "def ID3_chooseBestFeatureToSplit(dataset):\n",
    "    numFeatures = len(dataset[0]) - 1\n",
    "    baseEnt = cal_entropy(dataset)\n",
    "    bestInfoGain = 0.0\n",
    "    bestFeature = -1\n",
    "    for i in range(numFeatures):  # 遍历所有特征\n",
    "        # for example in dataset:\n",
    "        # featList=example[i]\n",
    "        featList = [example[i] for example in dataset]\n",
    "        uniqueVals = set(featList)  # 将特征列表创建成为set集合，元素不可重复。创建唯一的分类标签列表\n",
    "        newEnt = 0.0\n",
    "        for value in uniqueVals:  # 计算每种划分方式的信息熵\n",
    "            subdataset = splitdataset(dataset, i, value)\n",
    "            p = len(subdataset) / float(len(dataset))\n",
    "            newEnt += p * cal_entropy(subdataset)\n",
    "        infoGain = baseEnt - newEnt\n",
    "        print(u\"ID3中第%d个特征的信息增益为：%.3f\" % (i, infoGain))\n",
    "        if (infoGain > bestInfoGain):\n",
    "            bestInfoGain = infoGain  # 计算最好的信息增益\n",
    "            bestFeature = i\n",
    "    return bestFeature\n",
    "\n",
    "\n",
    "# C4.5算法\n",
    "def C45_chooseBestFeatureToSplit(dataset):\n",
    "    numFeatures = len(dataset[0]) - 1\n",
    "    baseEnt = cal_entropy(dataset)\n",
    "    bestInfoGain_ratio = 0.0\n",
    "    bestFeature = -1\n",
    "    for i in range(numFeatures):  # 遍历所有特征\n",
    "        featList = [example[i] for example in dataset]\n",
    "        uniqueVals = set(featList)  # 将特征列表创建成为set集合，元素不可重复。创建唯一的分类标签列表\n",
    "        newEnt = 0.0\n",
    "        IV = 0.0\n",
    "        for value in uniqueVals:  # 计算每种划分方式的信息熵\n",
    "            subdataset = splitdataset(dataset, i, value)\n",
    "            p = len(subdataset) / float(len(dataset))\n",
    "            newEnt += p * cal_entropy(subdataset)\n",
    "            IV = IV - p * log(p, 2)\n",
    "        infoGain = baseEnt - newEnt\n",
    "        if (IV == 0):  # fix the overflow bug\n",
    "            continue\n",
    "        infoGain_ratio = infoGain / IV  # 这个feature的infoGain_ratio\n",
    "        print(u\"C4.5中第%d个特征的信息增益率为：%.3f\" % (i, infoGain_ratio))\n",
    "        if (infoGain_ratio > bestInfoGain_ratio):  # 选择最大的gain ratio\n",
    "            bestInfoGain_ratio = infoGain_ratio\n",
    "            bestFeature = i  # 选择最大的gain ratio对应的feature\n",
    "    return bestFeature\n",
    "\n",
    "\n",
    "# CART算法\n",
    "def CART_chooseBestFeatureToSplit(dataset):\n",
    "    numFeatures = len(dataset[0]) - 1\n",
    "    bestGini = 999999.0\n",
    "    bestFeature = -1\n",
    "    for i in range(numFeatures):\n",
    "        featList = [example[i] for example in dataset]\n",
    "        uniqueVals = set(featList)\n",
    "        gini = 0.0\n",
    "        for value in uniqueVals:\n",
    "            subdataset = splitdataset(dataset, i, value)\n",
    "            p = len(subdataset) / float(len(dataset))\n",
    "            subp = len(splitdataset(subdataset, -1, dataset[0][-1])) / float(len(subdataset))\n",
    "        gini += p * (1.0 - pow(subp, 2) - pow(1 - subp, 2))\n",
    "        print(u\"CART中第%d个特征的基尼值为：%.3f\" % (i, gini))\n",
    "        if (gini < bestGini):\n",
    "            bestGini = gini\n",
    "            bestFeature = i\n",
    "    return bestFeature\n",
    "\n",
    "\n",
    "def majorityCnt(classList):\n",
    "    classCont = {}\n",
    "    for vote in classList:\n",
    "        if vote not in classCont.keys():\n",
    "            classCont[vote] = 0\n",
    "        classCont[vote] += 1\n",
    "    sortedClassCont = sorted(classCont.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedClassCont[0][0]\n",
    "\n",
    "# 利用ID3算法创建决策树\n",
    "def ID3_createTree(dataset, labels, test_dataset):\n",
    "    classList = [example[-1] for example in dataset]\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        # 类别完全相同，停止划分\n",
    "        return classList[0]\n",
    "    if len(dataset[0]) == 1:\n",
    "        # 遍历完所有特征时返回出现次数最多的\n",
    "        return majorityCnt(classList)\n",
    "    bestFeat = ID3_chooseBestFeatureToSplit(dataset)\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "    print(u\"此时最优索引为：\" + (bestFeatLabel))\n",
    "\n",
    "    ID3Tree = {bestFeatLabel: {}}\n",
    "    del (labels[bestFeat])\n",
    "    # 得到列表包括节点所有的属性值\n",
    "    featValues = [example[bestFeat] for example in dataset]\n",
    "    uniqueVals = set(featValues)\n",
    "\n",
    "    if pre_pruning:\n",
    "        ans = []\n",
    "        for index in range(len(test_dataset)):\n",
    "            ans.append(test_dataset[index][-1])\n",
    "        result_counter = Counter()\n",
    "        for vec in dataset:\n",
    "            result_counter[vec[-1]] += 1\n",
    "        leaf_output = result_counter.most_common(1)[0][0]\n",
    "        root_acc = cal_acc(test_output=[leaf_output] * len(test_dataset), label=ans)\n",
    "        outputs = []\n",
    "        ans = []\n",
    "        for value in uniqueVals:\n",
    "            cut_testset = splitdataset(test_dataset, bestFeat, value)\n",
    "            cut_dataset = splitdataset(dataset, bestFeat, value)\n",
    "            for vec in cut_testset:\n",
    "                ans.append(vec[-1])\n",
    "            result_counter = Counter()\n",
    "            for vec in cut_dataset:\n",
    "                result_counter[vec[-1]] += 1\n",
    "            leaf_output = result_counter.most_common(1)[0][0]\n",
    "            outputs += [leaf_output] * len(cut_testset)\n",
    "        cut_acc = cal_acc(test_output=outputs, label=ans)\n",
    "\n",
    "        if cut_acc <= root_acc:\n",
    "            return leaf_output\n",
    "\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:]\n",
    "        ID3Tree[bestFeatLabel][value] = ID3_createTree(\n",
    "            splitdataset(dataset, bestFeat, value),\n",
    "            subLabels,\n",
    "            splitdataset(test_dataset, bestFeat, value))\n",
    "\n",
    "    if post_pruning:\n",
    "        tree_output = classifytest(ID3Tree,\n",
    "                                   featLabels=['年龄','手术时间','腋窝结节数量','死亡时间','种类'],\n",
    "                                   testDataSet=test_dataset)\n",
    "        ans = []\n",
    "        for vec in test_dataset:\n",
    "            ans.append(vec[-1])\n",
    "        root_acc = cal_acc(tree_output, ans)\n",
    "        result_counter = Counter()\n",
    "        for vec in dataset:\n",
    "            result_counter[vec[-1]] += 1\n",
    "        leaf_output = result_counter.most_common(1)[0][0]\n",
    "        cut_acc = cal_acc([leaf_output] * len(test_dataset), ans)\n",
    "\n",
    "        if cut_acc >= root_acc:\n",
    "            return leaf_output\n",
    "\n",
    "    return ID3Tree\n",
    "\n",
    "\n",
    "def C45_createTree(dataset, labels, test_dataset):\n",
    "    classList = [example[-1] for example in dataset]\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        # 类别完全相同，停止划分\n",
    "        return classList[0]\n",
    "    if len(dataset[0]) == 1:\n",
    "        # 遍历完所有特征时返回出现次数最多的\n",
    "        return majorityCnt(classList)\n",
    "    bestFeat = C45_chooseBestFeatureToSplit(dataset)\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "    print(u\"此时最优索引为：\" + (bestFeatLabel))\n",
    "    C45Tree = {bestFeatLabel: {}}\n",
    "    del (labels[bestFeat])\n",
    "    # 得到列表包括节点所有的属性值\n",
    "    featValues = [example[bestFeat] for example in dataset]\n",
    "    uniqueVals = set(featValues)\n",
    "\n",
    "    if pre_pruning:\n",
    "        ans = []\n",
    "        for index in range(len(test_dataset)):\n",
    "            ans.append(test_dataset[index][-1])\n",
    "        result_counter = Counter()\n",
    "        for vec in dataset:\n",
    "            result_counter[vec[-1]] += 1\n",
    "        leaf_output = result_counter.most_common(1)[0][0]\n",
    "        root_acc = cal_acc(test_output=[leaf_output] * len(test_dataset), label=ans)\n",
    "        outputs = []\n",
    "        ans = []\n",
    "        for value in uniqueVals:\n",
    "            cut_testset = splitdataset(test_dataset, bestFeat, value)\n",
    "            cut_dataset = splitdataset(dataset, bestFeat, value)\n",
    "            for vec in cut_testset:\n",
    "                ans.append(vec[-1])\n",
    "            result_counter = Counter()\n",
    "            for vec in cut_dataset:\n",
    "                result_counter[vec[-1]] += 1\n",
    "            leaf_output = result_counter.most_common(1)[0][0]\n",
    "            outputs += [leaf_output] * len(cut_testset)\n",
    "        cut_acc = cal_acc(test_output=outputs, label=ans)\n",
    "\n",
    "        if cut_acc <= root_acc:\n",
    "            return leaf_output\n",
    "\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:]\n",
    "        C45Tree[bestFeatLabel][value] = C45_createTree(\n",
    "            splitdataset(dataset, bestFeat, value),\n",
    "            subLabels,\n",
    "            splitdataset(test_dataset, bestFeat, value))\n",
    "\n",
    "    if post_pruning:\n",
    "        tree_output = classifytest(C45Tree,\n",
    "                                   featLabels=['年龄','手术时间','腋窝结节数量','死亡时间','种类'],\n",
    "                                   testDataSet=test_dataset)\n",
    "        ans = []\n",
    "        for vec in test_dataset:\n",
    "            ans.append(vec[-1])\n",
    "        root_acc = cal_acc(tree_output, ans)\n",
    "        result_counter = Counter()\n",
    "        for vec in dataset:\n",
    "            result_counter[vec[-1]] += 1\n",
    "        leaf_output = result_counter.most_common(1)[0][0]\n",
    "        cut_acc = cal_acc([leaf_output] * len(test_dataset), ans)\n",
    "\n",
    "        if cut_acc >= root_acc:\n",
    "            return leaf_output\n",
    "\n",
    "    return C45Tree\n",
    "\n",
    "\n",
    "def CART_createTree(dataset, labels, test_dataset):\n",
    "    classList = [example[-1] for example in dataset]\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        # 类别完全相同，停止划分\n",
    "        return classList[0]\n",
    "    if len(dataset[0]) == 1:\n",
    "        # 遍历完所有特征时返回出现次数最多的\n",
    "        return majorityCnt(classList)\n",
    "    bestFeat = CART_chooseBestFeatureToSplit(dataset)\n",
    "    # print(u\"此时最优索引为：\"+str(bestFeat))\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "    print(u\"此时最优索引为：\" + (bestFeatLabel))\n",
    "    CARTTree = {bestFeatLabel: {}}\n",
    "    del (labels[bestFeat])\n",
    "    # 得到列表包括节点所有的属性值\n",
    "    featValues = [example[bestFeat] for example in dataset]\n",
    "    uniqueVals = set(featValues)\n",
    "\n",
    "    if pre_pruning:\n",
    "        ans = []\n",
    "        for index in range(len(test_dataset)):\n",
    "            ans.append(test_dataset[index][-1])\n",
    "        result_counter = Counter()\n",
    "        for vec in dataset:\n",
    "            result_counter[vec[-1]] += 1\n",
    "        leaf_output = result_counter.most_common(1)[0][0]\n",
    "        root_acc = cal_acc(test_output=[leaf_output] * len(test_dataset), label=ans)\n",
    "        outputs = []\n",
    "        ans = []\n",
    "        for value in uniqueVals:\n",
    "            cut_testset = splitdataset(test_dataset, bestFeat, value)\n",
    "            cut_dataset = splitdataset(dataset, bestFeat, value)\n",
    "            for vec in cut_testset:\n",
    "                ans.append(vec[-1])\n",
    "            result_counter = Counter()\n",
    "            for vec in cut_dataset:\n",
    "                result_counter[vec[-1]] += 1\n",
    "            leaf_output = result_counter.most_common(1)[0][0]\n",
    "            outputs += [leaf_output] * len(cut_testset)\n",
    "        cut_acc = cal_acc(test_output=outputs, label=ans)\n",
    "\n",
    "        if cut_acc <= root_acc:\n",
    "            return leaf_output\n",
    "\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:]\n",
    "        CARTTree[bestFeatLabel][value] = CART_createTree(\n",
    "            splitdataset(dataset, bestFeat, value),\n",
    "            subLabels,\n",
    "            splitdataset(test_dataset, bestFeat, value))\n",
    "\n",
    "        if post_pruning:\n",
    "            tree_output = classifytest(CARTTree,\n",
    "                                       featLabels=['年龄','手术时间','腋窝结节数量','死亡时间','种类'],\n",
    "                                       testDataSet=test_dataset)\n",
    "            ans = []\n",
    "            for vec in test_dataset:\n",
    "                ans.append(vec[-1])\n",
    "            root_acc = cal_acc(tree_output, ans)\n",
    "            result_counter = Counter()\n",
    "            for vec in dataset:\n",
    "                result_counter[vec[-1]] += 1\n",
    "            leaf_output = result_counter.most_common(1)[0][0]\n",
    "            cut_acc = cal_acc([leaf_output] * len(test_dataset), ans)\n",
    "\n",
    "            if cut_acc >= root_acc:\n",
    "                return leaf_output\n",
    "\n",
    "    return CARTTree\n",
    "\n",
    "\n",
    "def classify(inputTree, featLabels, testVec):\n",
    "    firstStr = list(inputTree.keys())[0]\n",
    "    secondDict = inputTree[firstStr]\n",
    "    featIndex = featLabels.index(firstStr)\n",
    "    classLabel = \"\"\n",
    "    for key in secondDict.keys():\n",
    "        if testVec[featIndex] == key:\n",
    "            if type(secondDict[key]).__name__ == 'dict':\n",
    "                classLabel = classify(secondDict[key], featLabels, testVec)\n",
    "            else:\n",
    "                classLabel = secondDict[key]\n",
    "    return classLabel\n",
    "\n",
    "\n",
    "def classifytest(inputTree, featLabels, testDataSet):\n",
    "    \"\"\"\n",
    "    输入：决策树，分类标签，测试数据集\n",
    "    输出：决策结果\n",
    "    描述：跑决策树\n",
    "    \"\"\"\n",
    "    classLabelAll = []\n",
    "    for testVec in testDataSet:\n",
    "        classLabelAll.append(classify(inputTree, featLabels, testVec))\n",
    "    return classLabelAll\n",
    "\n",
    "\n",
    "def cal_acc(test_output, label):\n",
    "    \"\"\"\n",
    "    :param test_output: the output of testset\n",
    "    :param label: the answer\n",
    "    :return: the acc of\n",
    "    \"\"\"\n",
    "    assert len(test_output) == len(label)\n",
    "    if(len(test_output)==0):\n",
    "        print('over')\n",
    "    count = 0\n",
    "    if len(test_output)==0:\n",
    "        return count\n",
    "    for index in range(len(test_output)):\n",
    "        if test_output[index] == label[index]:\n",
    "            count += 1\n",
    "    return float(count / len(test_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集长度 216\n",
      "Ent(D): 0.8587103706410477\n",
      "ID3中第0个特征的信息增益为：0.140\n",
      "ID3中第1个特征的信息增益为：0.043\n",
      "ID3中第2个特征的信息增益为：0.179\n",
      "此时最优索引为：腋窝结节数量\n",
      "ID3中第0个特征的信息增益为：1.000\n",
      "ID3中第1个特征的信息增益为：1.000\n",
      "此时最优索引为：年龄\n",
      "ID3中第0个特征的信息增益为：0.223\n",
      "ID3中第1个特征的信息增益为：0.084\n",
      "此时最优索引为：年龄\n",
      "ID3中第0个特征的信息增益为：0.650\n",
      "此时最优索引为：手术时间\n",
      "ID3中第0个特征的信息增益为：0.811\n",
      "此时最优索引为：手术时间\n",
      "ID3中第0个特征的信息增益为：0.918\n",
      "此时最优索引为：手术时间\n",
      "ID3中第0个特征的信息增益为：1.000\n",
      "此时最优索引为：手术时间\n",
      "ID3中第0个特征的信息增益为：0.252\n",
      "此时最优索引为：手术时间\n",
      "ID3中第0个特征的信息增益为：1.000\n",
      "此时最优索引为：手术时间\n",
      "ID3中第0个特征的信息增益为：0.252\n",
      "此时最优索引为：手术时间\n",
      "ID3中第0个特征的信息增益为：0.811\n",
      "此时最优索引为：手术时间\n",
      "ID3中第0个特征的信息增益为：0.577\n",
      "此时最优索引为：手术时间\n",
      "ID3中第0个特征的信息增益为：0.918\n",
      "此时最优索引为：手术时间\n",
      "ID3中第0个特征的信息增益为：0.811\n",
      "ID3中第1个特征的信息增益为：0.811\n",
      "此时最优索引为：年龄\n",
      "ID3中第0个特征的信息增益为：0.842\n",
      "ID3中第1个特征的信息增益为：0.842\n",
      "此时最优索引为：年龄\n",
      "ID3中第0个特征的信息增益为：1.000\n",
      "此时最优索引为：手术时间\n",
      "ID3中第0个特征的信息增益为：0.670\n",
      "ID3中第1个特征的信息增益为：0.416\n",
      "此时最优索引为：年龄\n",
      "ID3中第0个特征的信息增益为：0.000\n",
      "此时最优索引为：种类\n",
      "ID3中第0个特征的信息增益为：0.918\n",
      "此时最优索引为：手术时间\n",
      "ID3中第0个特征的信息增益为：0.722\n",
      "ID3中第1个特征的信息增益为：0.322\n",
      "此时最优索引为：年龄\n",
      "ID3中第0个特征的信息增益为：0.704\n",
      "ID3中第1个特征的信息增益为：0.954\n",
      "此时最优索引为：手术时间\n",
      "ID3中第0个特征的信息增益为：0.918\n",
      "ID3中第1个特征的信息增益为：0.918\n",
      "此时最优索引为：年龄\n",
      "ID3中第0个特征的信息增益为：0.481\n",
      "ID3中第1个特征的信息增益为：0.357\n",
      "此时最优索引为：年龄\n",
      "ID3中第0个特征的信息增益为：1.000\n",
      "此时最优索引为：手术时间\n",
      "ID3中第0个特征的信息增益为：1.000\n",
      "此时最优索引为：手术时间\n",
      "ID3中第0个特征的信息增益为：0.918\n",
      "ID3中第1个特征的信息增益为：0.918\n",
      "此时最优索引为：年龄\n",
      "ID3中第0个特征的信息增益为：0.918\n",
      "ID3中第1个特征的信息增益为：0.918\n",
      "此时最优索引为：年龄\n",
      "ID3中第0个特征的信息增益为：1.000\n",
      "ID3中第1个特征的信息增益为：1.000\n",
      "此时最优索引为：年龄\n",
      "ID3中第0个特征的信息增益为：1.000\n",
      "ID3中第1个特征的信息增益为：0.667\n",
      "此时最优索引为：年龄\n",
      "ID3中第0个特征的信息增益为：0.918\n",
      "ID3中第1个特征的信息增益为：0.918\n",
      "此时最优索引为：年龄\n",
      "ID3中第0个特征的信息增益为：0.811\n",
      "ID3中第1个特征的信息增益为：0.811\n",
      "此时最优索引为：年龄\n",
      "ID3中第0个特征的信息增益为：0.918\n",
      "ID3中第1个特征的信息增益为：0.918\n",
      "此时最优索引为：年龄\n",
      "ID3desicionTree:\n",
      " {'腋窝结节数量': {' 19': {'年龄': {'62': ' 2', '54': ' 1'}}, ' 0': {'年龄': {'61': {'手术时间': {' 64': ' 1', ' 68': ' 1', ' 65': ' 2', ' 59': ' 1'}}, '73': ' 1', '45': {'手术时间': {' 64': ' 1', ' 68': ' 1', ' 67': ' 1', ' 66': ' 2'}}, '68': ' 1', '39': {'手术时间': {' 66': ' 2', ' 67': ' 1', ' 63': ' 1'}}, '47': {'手术时间': {' 65': ' 2', ' 62': ' 2', ' 67': ' 1', ' 61': ' 1'}}, '42': ' 1', '37': ' 1', '56': ' 1', '53': ' 1', '51': ' 1', '54': ' 1', '46': ' 1', '48': ' 1', '63': ' 1', '55': ' 1', '65': {'手术时间': {' 64': ' 1', ' 58': ' 1'}}, '44': ' 1', '59': ' 1', '60': ' 1', '57': ' 1', '34': {'手术时间': {' 60': ' 1', ' 59': ' 2'}}, '50': {'手术时间': {' 64': ' 1', ' 61': ' 1'}}, '58': ' 1', '70': ' 1', '49': {'手术时间': {' 66': ' 1', ' 62': ' 1', ' 61': ' 1', ' 63': ' 2'}}, '35': ' 1', '62': ' 1', '40': ' 1', '41': {'手术时间': {' 64': ' 1', ' 67': ' 2', ' 58': ' 1', ' 65': ' 1', ' 59': ' 1'}}, '52': ' 1', '69': ' 1', '36': ' 1', '74': ' 1', '66': ' 1', '67': ' 1', '38': ' 1', '64': ' 1', '72': ' 1', '43': {'手术时间': {' 65': ' 1', ' 64': ' 2'}}}}, ' 20': ' 1', ' 28': ' 1', ' 5': {'年龄': {'61': ' 2', '52': ' 1', '57': ' 2', '46': ' 2'}}, ' 30': ' 1', ' 3': {'年龄': {'51': ' 2', '46': {'手术时间': {' 58': ' 1', ' 69': ' 2'}}, '52': ' 2', '58': ' 1', '74': ' 2', '49': ' 1', '30': ' 1', '47': ' 1', '59': ' 1', '53': ' 2'}}, ' 1': {'年龄': {'61': ' 2', '45': {'种类': {' 1': ' 1', ' 2': ' 2'}}, '42': {'手术时间': {' 69': ' 2', ' 60': ' 1', ' 63': ' 1'}}, '53': ' 2', '56': ' 1', '51': ' 1', '54': ' 1', '55': ' 1', '63': ' 2', '65': ' 1', '59': ' 1', '60': ' 1', '57': ' 2', '34': ' 1', '75': ' 1', '50': ' 1', '49': ' 1', '78': ' 2', '52': ' 1', '36': ' 1', '67': ' 2', '38': ' 1'}}, ' 7': {'年龄': {'51': ' 1', '54': ' 1', '48': ' 2', '34': ' 1'}}, ' 4': {'手术时间': {' 66': ' 2', ' 61': ' 1', ' 60': ' 1', ' 64': ' 1', ' 58': ' 2', ' 68': ' 1'}}, ' 23': ' 2', ' 25': ' 1', ' 18': ' 1', ' 35': ' 2', ' 17': ' 2', ' 8': {'年龄': {'61': ' 1', '41': ' 1', '48': ' 1', '69': ' 2', '67': ' 2'}}, ' 2': {'年龄': {'43': {'手术时间': {' 63': ' 1', ' 59': ' 2'}}, '83': ' 2', '50': ' 1', '58': ' 1', '65': {'手术时间': {' 61': ' 2', ' 59': ' 1'}}, '38': ' 1', '56': ' 1', '60': ' 1'}}, ' 22': ' 1', ' 24': ' 2', ' 10': {'年龄': {'33': ' 1', '49': ' 2', '34': ' 1'}}, ' 15': {'年龄': {'55': ' 2', '37': ' 1', '65': ' 2'}}, ' 46': ' 1', ' 21': ' 2', ' 14': {'年龄': {'70': ' 1', '57': ' 2'}}, ' 12': ' 1', ' 6': {'年龄': {'44': ' 2', '55': ' 2', '45': ' 2', '47': ' 1', '62': ' 1', '37': ' 1'}}, ' 13': {'年龄': {'62': ' 2', '66': ' 2', '35': ' 1'}}, ' 9': {'年龄': {'34': ' 2', '63': ' 1', '44': ' 2', '56': ' 2'}}, ' 11': {'年龄': {'38': ' 1', '48': ' 2'}}}}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    filename = 'haber_train.txt'\n",
    "    testfile = 'haber_test.txt'\n",
    "    #西瓜\n",
    "    # filename = 'xigua_trainset.txt'\n",
    "    # testfile = 'xigua_testset.txt'\n",
    "    # labels = ['色泽','根蒂','敲声','纹理','脐部','触感']\n",
    "    labels = ['年龄','手术时间','腋窝结节数量','死亡时间']\n",
    "    dataset, labels = read_dataset(filename)\n",
    "    # dataset,features=createDataSet()\n",
    "    # print('dataset', dataset)\n",
    "    # print(\"---------------------------------------------\")\n",
    "    print(u\"数据集长度\", len(dataset))\n",
    "    print(\"Ent(D):\", cal_entropy(dataset))\n",
    "    # print(\"---------------------------------------------\")\n",
    "\n",
    "    # print(u\"以下为首次寻找最优索引:\\n\")\n",
    "    # print(u\"ID3算法的最优特征索引为:\" + str(ID3_chooseBestFeatureToSplit(dataset)))\n",
    "    # print(\"--------------------------------------------------\")\n",
    "    # print(u\"C4.5算法的最优特征索引为:\" + str(C45_chooseBestFeatureToSplit(dataset)))\n",
    "    # print(\"--------------------------------------------------\")\n",
    "    # print(u\"CART算法的最优特征索引为:\" + str(CART_chooseBestFeatureToSplit(dataset)))\n",
    "    # print(u\"首次寻找最优索引结束！\")\n",
    "    # print(\"---------------------------------------------\")\n",
    "\n",
    "    # print(u\"下面开始创建相应的决策树-------\")\n",
    "\n",
    "    while True:\n",
    "        dec_tree = '1'\n",
    "        # ID3决策树\n",
    "        if dec_tree == '1':\n",
    "            labels_tmp = labels[:]  # 拷贝，createTree会改变labels\n",
    "            ID3desicionTree = ID3_createTree(dataset, labels_tmp, test_dataset=read_testset(testfile))\n",
    "            print('ID3desicionTree:\\n', ID3desicionTree)\n",
    "            # treePlotter.createPlot(ID3desicionTree)\n",
    "            dtplot.ID3_Tree(ID3desicionTree)\n",
    "            testSet = read_testset(testfile)\n",
    "            print(\"下面为测试数据集结果：\")\n",
    "            print('ID3_TestSet_classifyResult:\\n', classifytest(ID3desicionTree, labels, testSet))\n",
    "            print(\"---------------------------------------------\")\n",
    "\n",
    "        # C4.5决策树\n",
    "        if dec_tree == '2':\n",
    "            labels_tmp = labels[:]  # 拷贝，createTree会改变labels\n",
    "            C45desicionTree = C45_createTree(dataset, labels_tmp, test_dataset=read_testset(testfile))\n",
    "            print('C45desicionTree:\\n', C45desicionTree)\n",
    "            dtplot.C45_Tree(C45desicionTree)\n",
    "            testSet = read_testset(testfile)\n",
    "            print(\"下面为测试数据集结果：\")\n",
    "            print('C4.5_TestSet_classifyResult:\\n', classifytest(C45desicionTree, labels, testSet))\n",
    "            print(\"---------------------------------------------\")\n",
    "\n",
    "        # CART决策树\n",
    "        if dec_tree == '3':\n",
    "            labels_tmp = labels[:]  # 拷贝，createTree会改变labels\n",
    "            CARTdesicionTree = CART_createTree(dataset, labels_tmp, test_dataset=read_testset(testfile))\n",
    "            print('CARTdesicionTree:\\n', CARTdesicionTree)\n",
    "            dtplot.CART_Tree(CARTdesicionTree)\n",
    "            testSet = read_testset(testfile)\n",
    "            print(\"下面为测试数据集结果：\")\n",
    "            print('CART_TestSet_classifyResult:\\n', classifytest(CARTdesicionTree, labels, testSet))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0843aa2147bb7b68e1331c060614b1ebfeaba0f0db744f4b489daeb337a1f0b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
