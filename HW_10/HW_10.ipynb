{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!gdown --id'' --output train.npy\n",
                "!gdown --id'' --output test.npy\n",
                "\n",
                "import numpy as np\n",
                "\n",
                "train = np.load('train.npy',allow_pickle=True)\n",
                "test = np.load('test.npy',allow_pickle=True)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#半监督 anomaly dection\n",
                "#检测出测试集中没有的 label\n",
                "task ='pca'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#KNN\n",
                "from sklearn.cluster import MiniBatchKMeans\n",
                "from sklearn.metrics import f1_score,pairwise_distances,roc_auc_score\n",
                "from scipy.cluster.vq import vq,kmeans\n",
                "\n",
                "if task =='knn':\n",
                "    x = train.reshape(len(train),-1)\n",
                "    y = train.reshape(len(test),-1)\n",
                "    scores = list()\n",
                "    for n in range(1,10):\n",
                "        kmeans_x = MiniBatchKMeans(n_clusters=n,batch_size =100).fit(x)\n",
                "        y_cluster = kmeans_x.predict(y)\n",
                "        y_dist = np.sum(np.square(kmeans_x.cluster_centers_[y_cluster]-y),axis=1)\n",
                "\n",
                "        y_pred = y_dist\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#PCA\n",
                "from sklearn.decomposition import PCA\n",
                "\n",
                "if task =='pca':\n",
                "    x = train.reshape(len(train),-1)\n",
                "    y = train.reshape(len(test),-1)\n",
                "    pca =PCA(n_components=2).fit(x)\n",
                "\n",
                "    y_projected = pca.transform(y)\n",
                "    y_reconstructed = pca.inverse_transform(y_projected)\n",
                "    dist = np.sqrt(np.sum(np.square(y_reconstructed-y).reshape(len(y),-1),axis=1))\n",
                "\n",
                "    y_pred = dist\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Autoencoder\n",
                "import torch \n",
                "from torch import nn \n",
                "import torch.nn.functional as F\n",
                "\n",
                "class fcn_autoencoder(nn.Module):\n",
                "    def __init__(self):\n",
                "        super(fcn_autoencoder,self).__init__()\n",
                "        self.encoder = nn.Sequential(\n",
                "            nn.Linear(32*32*3,128),\n",
                "            nn.ReLU(True),\n",
                "            nn.Linear(128,64),\n",
                "            nn.ReLU(True),\n",
                "            nn.Linear(64,12),\n",
                "            nn.ReLU(True),\n",
                "            nn.Linear(12,3)\n",
                "        )\n",
                "        self.decoder =nn.Sequential(\n",
                "            nn.Linear(3,12),\n",
                "            nn.ReLU(True),\n",
                "            nn.Linear(12,64),\n",
                "            nn.ReLU(True),\n",
                "            nn.Linear(64,128),\n",
                "            nn.ReLU(True),\n",
                "            nn.Linear(128,3*32*32),\n",
                "            nn.Tanh()\n",
                "        )\n",
                "    \n",
                "    def forward(self,x):\n",
                "        x = self.encoder(x)\n",
                "        x = self.decoder(x)\n",
                "        return x\n",
                "\n",
                "class conv_autoencoder(nn.Module):\n",
                "    def __init__(self):\n",
                "        super(conv_autoencoder,self).__init__()\n",
                "        self.encoder = nn.Sequential(\n",
                "            nn.Conv2d(3,12,4,stride=2,padding=1),\n",
                "            nn.ReLU(),\n",
                "            nn.Conv2d(12,24,4,stride=2,padding=1),\n",
                "            nn.ReLU(),\n",
                "            nn.Conv2d(24,48,4,stride=2,padding=1),\n",
                "            nn.ReLU()\n",
                "        )\n",
                "        self.decoder = nn.Sequential(\n",
                "            nn.ConvTranspose2d(48,24,4,stride=2,padding=1),\n",
                "            nn.ReLU(),\n",
                "            nn.ConvTranspose2d(24,12,4,stride=2,padding=1),\n",
                "            nn.ReLU(),\n",
                "            nn.ConvTranspose2d(12,3,4,stride=2,padding=1),\n",
                "            nn.ReLU(),\n",
                "            nn.Tanh()\n",
                "        )\n",
                "    \n",
                "    def forward(self,x):\n",
                "        x =self.encoder(x)\n",
                "        x = self.decoder(x)\n",
                "        return x \n",
                "    \n",
                "class VAE(nn.Module):\n",
                "    def __init__(self):\n",
                "        super(VAE,self).__init__()\n",
                "        self.fc1 = nn.Linear(32*32*3,400)\n",
                "        self.fc21 = nn.Linear(400,20)\n",
                "        self.fc22 = nn.Linear(400,20)\n",
                "        self.fc3 = nn.Linear(20,400)\n",
                "        self.fc4 = nn.Linear(400,32*32*3)\n",
                "    \n",
                "    def encode(self,x):\n",
                "        h1 =F.relu(self.fc1(x))\n",
                "        return self.fc21(h1),self.fc22(h1)\n",
                "    \n",
                "    def reparametrize(self,mu,logvar):\n",
                "        std = logvar.mul(0.5).exp_()\n",
                "        if torch.cuda.is_available():\n",
                "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
                "        else:\n",
                "            eps = torch.FloatTensor(std.size()).normal_()\n",
                "        eps = Variable(eps)\n",
                "        return eps.mul(std).add_(mu)\n",
                "\n",
                "    def decode(self,z):\n",
                "        h3 = F.relu(self.fc3(z))\n",
                "        return F.sigmoid(self.fc4(h3))\n",
                "\n",
                "    def forward(self,x):\n",
                "        mu,logvar = self.encode(x)\n",
                "        z = self.reparametrize(mu,logvar)\n",
                "        return self.decode(z),mu,logvar\n",
                "\n",
                "\n",
                "def loss_vae(recon_x,x,mu,logvar,criterion):\n",
                "    mse = criterion(recon_x,x)\n",
                "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
                "    KLD = torch.sum(KLD_element).mul_(0.5)\n",
                "    return mse+KLD\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#training"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "0843aa2147bb7b68e1331c060614b1ebfeaba0f0db744f4b489daeb337a1f0b2"
        },
        "kernelspec": {
            "display_name": "Python 3.8.3 64-bit",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.3"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
