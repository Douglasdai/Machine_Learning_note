{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport cv2\nimport numpy as np\nimport pandas as pd \nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset,DataLoader\nimport torch.nn as nn\nfrom tqdm import tqdm\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.style.use('ggplot')\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-12-14T15:06:26.117432Z","iopub.execute_input":"2021-12-14T15:06:26.117715Z","iopub.status.idle":"2021-12-14T15:06:28.217306Z","shell.execute_reply.started":"2021-12-14T15:06:26.117685Z","shell.execute_reply":"2021-12-14T15:06:28.21631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"make dataset to read ","metadata":{}},{"cell_type":"code","source":"#dataset\nclass ImageDataset(Dataset):\n    def __init__(self, csv, train, test):\n        self.csv = csv\n        self.train = train\n        self.test = test\n        self.all_image_names = self.csv[:]['Id']\n        self.all_labels = np.array(self.csv.drop(['Id', 'Genre'], axis=1))\n        self.train_ratio = int(0.85 * len(self.csv))\n        self.valid_ratio = len(self.csv) - self.train_ratio\n\n        # set the training data images and labels\n        if self.train == True:\n            print(f\"Number of training images: {self.train_ratio}\")\n            self.image_names = list(self.all_image_names[:self.train_ratio])\n            self.labels = list(self.all_labels[:self.train_ratio])\n\n            # define the training transforms\n            self.transform = transforms.Compose([\n                transforms.ToPILImage(),\n                transforms.Resize((400, 400)),\n                transforms.RandomHorizontalFlip(p=0.5),\n                transforms.RandomRotation(degrees=45),\n                transforms.ToTensor(),\n            ])\n\n        # set the validation data images and labels\n        elif self.train == False and self.test == False:\n            print(f\"Number of validation images: {self.valid_ratio}\")\n            self.image_names = list(self.all_image_names[-self.valid_ratio:-10])\n            self.labels = list(self.all_labels[-self.valid_ratio:])\n\n            # define the validation transforms\n            self.transform = transforms.Compose([\n                transforms.ToPILImage(),\n                transforms.Resize((400, 400)),\n                transforms.ToTensor(),\n            ])\n\n        # set the test data images and labels, only last 10 images\n        # this, we will use in a separate inference script\n        elif self.test == True and self.train == False:\n            self.image_names = list(self.all_image_names[-10:])\n            self.labels = list(self.all_labels[-10:])\n\n             # define the test transforms\n            self.transform = transforms.Compose([\n                transforms.ToPILImage(),\n                transforms.ToTensor(),\n            ])\n\n    def __len__(self):\n        return len(self.image_names)\n    \n    def __getitem__(self, index):\n        image = cv2.imread(f\"../input/movie-classifier/Multi_Label_dataset/Images/{self.image_names[index]}.jpg\")\n        # convert the image from BGR to RGB color format\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        # apply image transforms\n        image = self.transform(image)\n        targets = self.labels[index]\n        \n        return {\n            'image': torch.tensor(image, dtype=torch.float32),\n            'label': torch.tensor(targets, dtype=torch.float32)\n        }\n","metadata":{"execution":{"iopub.status.busy":"2021-12-14T15:06:28.219031Z","iopub.execute_input":"2021-12-14T15:06:28.219283Z","iopub.status.idle":"2021-12-14T15:06:28.232766Z","shell.execute_reply.started":"2021-12-14T15:06:28.219252Z","shell.execute_reply":"2021-12-14T15:06:28.232181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"import model, here use the resnet50 and add a linear layer change 2048 to 25 ","metadata":{}},{"cell_type":"code","source":"from torchvision import models as models\ndef model(pretrained, requires_grad):\n    model = models.resnet50(progress=True, pretrained=pretrained)\n    # to freeze the hidden layers\n    if requires_grad == False:\n        for param in model.parameters():\n            param.requires_grad = False\n    # to train the hidden layers\n    elif requires_grad == True:\n        for param in model.parameters():\n            param.requires_grad = True\n    # make the classification layer learnable\n    # we have 25 classes in total\n    model.fc = nn.Linear(2048, 25)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-14T15:06:28.233827Z","iopub.execute_input":"2021-12-14T15:06:28.23431Z","iopub.status.idle":"2021-12-14T15:06:28.250895Z","shell.execute_reply.started":"2021-12-14T15:06:28.234249Z","shell.execute_reply":"2021-12-14T15:06:28.25016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"add some evaluation indicators, such as mAP,AUC and F1 score","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import average_precision_score,roc_auc_score\ndef compute_mAP(outputs,labels):\n    y_true = labels.cpu().detach().numpy()\n    y_pred = outputs.cpu().detach().numpy()\n    AP = []\n    for i in range(y_true.shape[0]):\n        AP.append(average_precision_score(y_true[i],y_pred[i]))\n    return np.mean(AP)\n\ndef comput_roc(outputs,labels):\n    y_true = labels.cpu().detach().numpy()\n    y_pred = outputs.cpu().detach().numpy()\n    ROC = []\n    for i in range(y_true.shape[0]):\n        ROC.append(roc_auc_score(y_true[i],y_pred[i]))\n    return np.mean(ROC)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T15:06:28.252381Z","iopub.execute_input":"2021-12-14T15:06:28.252703Z","iopub.status.idle":"2021-12-14T15:06:29.111917Z","shell.execute_reply.started":"2021-12-14T15:06:28.252665Z","shell.execute_reply":"2021-12-14T15:06:29.111151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score,recall_score,f1_score\ndef calculate_metrics(pred, target, threshold=0.5):\n    pred = np.array(pred > threshold, dtype=float)\n    return {'micro/precision': precision_score(y_true=target, y_pred=pred, average='micro'),\n            'micro/recall': recall_score(y_true=target, y_pred=pred, average='micro'),\n            'micro/f1': f1_score(y_true=target, y_pred=pred, average='micro'),\n            'macro/precision': precision_score(y_true=target, y_pred=pred, average='macro'),\n            'macro/recall': recall_score(y_true=target, y_pred=pred, average='macro'),\n            'macro/f1': f1_score(y_true=target, y_pred=pred, average='macro'),\n            'samples/precision': precision_score(y_true=target, y_pred=pred, average='samples'),\n            'samples/recall': recall_score(y_true=target, y_pred=pred, average='samples'),\n            'samples/f1': f1_score(y_true=target, y_pred=pred, average='samples'),\n            }","metadata":{"execution":{"iopub.status.busy":"2021-12-14T15:06:29.114206Z","iopub.execute_input":"2021-12-14T15:06:29.114488Z","iopub.status.idle":"2021-12-14T15:06:29.125453Z","shell.execute_reply.started":"2021-12-14T15:06:29.114455Z","shell.execute_reply":"2021-12-14T15:06:29.12466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"train function and valid function","metadata":{}},{"cell_type":"code","source":"# training function\ndef train(model, dataloader, optimizer, criterion, train_data, device):\n    print('Training')\n    model.train()\n    counter = 0\n    train_running_loss = 0.0\n    train_running_mAP = 0.0\n    train_running_ROC = 0.0\n    for i, data in tqdm(enumerate(dataloader), total=int(len(train_data)/dataloader.batch_size)):\n        counter += 1\n        data, target = data['image'].to(device), data['label'].to(device)\n        optimizer.zero_grad()\n        outputs = model(data)\n        # apply sigmoid activation to get all the outputs between 0 and 1\n        outputs = torch.sigmoid(outputs)\n        loss = criterion(outputs, target)\n        train_running_loss += loss.item()\n        train_running_mAP += compute_mAP(outputs,target)\n        train_running_ROC += comput_roc(outputs,target)\n        # backpropagation\n        loss.backward()\n        # update optimizer parameters\n        optimizer.step()\n        \n    train_loss = train_running_loss / counter\n    train_mAP = train_running_mAP/counter\n    train_ROC = train_running_ROC/counter\n    print(f\"Train mAP: {train_mAP:.4f}\")\n    print(f'Train ROC: {train_ROC:.4f}')\n    return train_loss,train_mAP,train_ROC","metadata":{"execution":{"iopub.status.busy":"2021-12-14T15:06:29.127949Z","iopub.execute_input":"2021-12-14T15:06:29.128664Z","iopub.status.idle":"2021-12-14T15:06:29.137967Z","shell.execute_reply.started":"2021-12-14T15:06:29.128616Z","shell.execute_reply":"2021-12-14T15:06:29.137248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# validation function\ndef validate(model, dataloader, criterion, val_data, device):\n    print('Validating')\n    model.eval()\n    counter = 0\n    val_running_loss = 0.0\n    val_running_mAP = 0.0\n    val_running_ROC = 0.0\n    with torch.no_grad():\n        model_result = []\n        targets = []\n        for i, data in tqdm(enumerate(dataloader), total=int(len(val_data)/dataloader.batch_size)):\n            counter += 1\n            data, target = data['image'].to(device), data['label'].to(device)\n            outputs = model(data)\n            # apply sigmoid activation to get all the outputs between 0 and 1\n            outputs = torch.sigmoid(outputs)\n            loss = criterion(outputs, target)\n            model_result.extend(outputs.cpu().numpy())\n            targets.extend(target.cpu().numpy())\n            val_running_mAP += compute_mAP(outputs,target)\n            val_running_ROC += comput_roc(outputs,target)\n            val_running_loss += loss.item()\n            \n        result = calculate_metrics(np.array(model_result), np.array(targets))\n        val_loss = val_running_loss / counter\n        val_mAP = val_running_mAP/counter\n        val_ROC = val_running_ROC/counter\n        print(\"epoch:{:2d}  test: \"\n                  \"micro f1: {:.3f} \"\n                  \"macro f1: {:.3f} \"\n                  \"samples f1: {:.3f}\".format(epoch,\n                                              result['micro/f1'],\n                                              result['macro/f1'],\n                                              result['samples/f1']))\n        print(f\"Val mAP: {val_mAP:.4f}\")\n        print(f'Val ROC: {val_ROC:.4f}')\n        return val_loss,val_mAP,val_ROC","metadata":{"execution":{"iopub.status.busy":"2021-12-14T15:06:29.139291Z","iopub.execute_input":"2021-12-14T15:06:29.139817Z","iopub.status.idle":"2021-12-14T15:06:29.151649Z","shell.execute_reply.started":"2021-12-14T15:06:29.139776Z","shell.execute_reply":"2021-12-14T15:06:29.150994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"some settings and you can train and output some evaluations ","metadata":{}},{"cell_type":"code","source":"#train\n# initialize the computation device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel2 = model(pretrained=True, requires_grad=False).to(device)\n# learning parameters\nlr = 0.0001\nepochs = 10\nbatch_size = 32\noptimizer = optim.Adam(model2.parameters(), lr=lr)\ncriterion = nn.BCELoss()\n# read the training csv file\ntrain_csv = pd.read_csv('../input/movie-classifier/Multi_Label_dataset/train.csv')\n# train dataset\ntrain_data = ImageDataset(\n    train_csv, train=True, test=False\n)\n# validation dataset\nvalid_data = ImageDataset(\n    train_csv, train=False, test=False\n)\n# train data loader\ntrain_loader = DataLoader(\n    train_data, \n    batch_size=batch_size,\n    shuffle=True\n)\n# validation data loader\nvalid_loader = DataLoader(\n    valid_data, \n    batch_size=batch_size,\n    shuffle=False\n)\ntrain_loss = []\nvalid_loss = []\ntrain_mAP = []\ntrain_ROC = []\nvalid_mAP = []\nvalid_ROC = []\nfor epoch in range(epochs):\n    print(f\"Epoch {epoch+1} of {epochs}\")\n    train_epoch_loss,train_epoch_mAP,train_epoch_ROC = train(\n        model2, train_loader, optimizer, criterion, train_data, device\n    )\n    valid_epoch_loss,val_epoch_mAP,val_epoch_ROC = validate(\n        model2, valid_loader, criterion, valid_data, device\n    )\n    train_loss.append(train_epoch_loss)\n    valid_loss.append(valid_epoch_loss)\n    train_mAP.append(train_epoch_mAP)\n    train_ROC.append(train_epoch_ROC)\n    valid_mAP.append(val_epoch_mAP)\n    valid_ROC.append(val_epoch_ROC)\n    print(f\"Train Loss: {train_epoch_loss:.4f}\")\n    print(f'Val Loss: {valid_epoch_loss:.4f}')","metadata":{"execution":{"iopub.status.busy":"2021-12-14T15:07:16.219994Z","iopub.execute_input":"2021-12-14T15:07:16.220638Z","iopub.status.idle":"2021-12-14T15:28:17.015718Z","shell.execute_reply.started":"2021-12-14T15:07:16.220602Z","shell.execute_reply":"2021-12-14T15:28:17.015021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"save the model and have a look at the loss","metadata":{}},{"cell_type":"code","source":"torch.save({\n            'epoch': epochs,\n            'model_state_dict': model2.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'loss': criterion,\n            }, './model.pth')\n# plot and save the train and validation line graphs\nplt.figure(figsize=(10, 7))\nplt.plot(train_loss, color='orange', label='train loss')\nplt.plot(valid_loss, color='red', label='validataion loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.savefig('../loss.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T15:29:35.181729Z","iopub.execute_input":"2021-12-14T15:29:35.182038Z","iopub.status.idle":"2021-12-14T15:29:35.787682Z","shell.execute_reply.started":"2021-12-14T15:29:35.182005Z","shell.execute_reply":"2021-12-14T15:29:35.786758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"watch the mAP and ROC","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 7))\nplt.plot(train_mAP, color='orange', label='train_mAP')\nplt.plot(train_ROC, color='red', label='train_ROC')\nplt.plot(valid_mAP, color='blue',label ='valid_mAP')\nplt.plot(valid_ROC, color='pink', label='valid_ROC')\nplt.xlabel('Epochs')\nplt.ylabel('ACC')\nplt.legend()\nplt.savefig('../ACC.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T15:29:54.013242Z","iopub.execute_input":"2021-12-14T15:29:54.013552Z","iopub.status.idle":"2021-12-14T15:29:54.360552Z","shell.execute_reply.started":"2021-12-14T15:29:54.013523Z","shell.execute_reply":"2021-12-14T15:29:54.359824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"to do some perdict and visulation","metadata":{}},{"cell_type":"code","source":"#watch the predict \n# initialize the computation device\nnet = model(pretrained=False, requires_grad=False).to(device)\n# load the model checkpoint\ncheckpoint = torch.load('./model.pth')\n# load model weights state_dict\nnet.load_state_dict(checkpoint['model_state_dict'])\nnet.eval()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T15:30:31.083443Z","iopub.execute_input":"2021-12-14T15:30:31.083728Z","iopub.status.idle":"2021-12-14T15:30:31.603382Z","shell.execute_reply.started":"2021-12-14T15:30:31.083698Z","shell.execute_reply":"2021-12-14T15:30:31.602691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv = pd.read_csv('../input/movie-classifier/Multi_Label_dataset/train.csv')\ngenres = train_csv.columns.values[2:]\n# prepare the test dataset and dataloader\ntest_data = ImageDataset(\n    train_csv, train=False, test=True\n)\ntest_loader = DataLoader(\n    test_data, \n    batch_size=1,\n    shuffle=False\n)\nfor counter, data in enumerate(test_loader):\n    image, target = data['image'].to(device), data['label']\n    # get all the index positions where value == 1\n    target_indices = [i for i in range(len(target[0])) if target[0][i] == 1]\n    # get the predictions by passing the image through the model\n    outputs = net(image)\n    outputs = torch.sigmoid(outputs)\n    outputs = outputs.detach().cpu()\n    sorted_indices = np.argsort(outputs[0])\n    best = sorted_indices[-3:]\n    string_predicted = ''\n    string_actual = ''\n    for i in range(len(best)):\n        string_predicted += f\"{genres[best[i]]}    \"\n    for i in range(len(target_indices)):\n        string_actual += f\"{genres[target_indices[i]]}    \"\n    image = image.squeeze(0)\n    image = image.detach().cpu().numpy()\n    image = np.transpose(image, (1, 2, 0))\n    plt.imshow(image)\n    plt.axis('off')\n    plt.title(f\"PREDICTED: {string_predicted}\\nACTUAL: {string_actual}\")\n    plt.savefig(f\"./inference_{counter}.jpg\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T15:30:47.739392Z","iopub.execute_input":"2021-12-14T15:30:47.73965Z","iopub.status.idle":"2021-12-14T15:30:49.130633Z","shell.execute_reply.started":"2021-12-14T15:30:47.739621Z","shell.execute_reply":"2021-12-14T15:30:49.129975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}