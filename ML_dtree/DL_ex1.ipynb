{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) 5\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "(X_train,Y_train),(X_test,Y_test) = mnist.load_data()\n",
    "#X 为图片 ，2维  y  为 label \n",
    "print(X_train.shape,Y_train.shape,Y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "# training 時做 data augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(), # 隨機將圖片水平翻轉\n",
    "    transforms.RandomRotation(15), # 隨機旋轉圖片\n",
    "    transforms.ToTensor(), # 將圖片轉成 Tensor，並把數值 normalize 到 [0,1] (data normalization)\n",
    "])\n",
    "# testing 時不需做 data augmentation\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),                                    \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, x, y=None, transform=None):\n",
    "        self.x = x\n",
    "        # label is required to be a LongTensor\n",
    "        self.y = y\n",
    "        if y is not None:\n",
    "            self.y = torch.LongTensor(y)\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, index):\n",
    "        X = self.x[index]\n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "        if self.y is not None:\n",
    "            Y = self.y[index]\n",
    "            return X, Y\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "train_set = ImgDataset(X_train,Y_train,train_transform)\n",
    "val_set = ImgDataset(X_test,Y_test,test_transform)\n",
    "train_loader = DataLoader(train_set,batch_size = batch_size,shuffle=True)\n",
    "val_loader = DataLoader(val_set,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "        # input 維度 [64,1, 28, 28]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, 1, 1),  # [64, 28, 28]\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [64, 14, 14]\n",
    "\n",
    "            nn.Conv2d(16, 32, 3, 1, 1), # [128, 14, 14]\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [128, 7, 7]\n",
    "            \n",
    "            nn.Conv2d(32, 64, 3, 1, 1), # [512, 7, 7]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64*7*7, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "# print(device)\n",
    "model = Classifier().to(device)\n",
    "cirection = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/030] 15.55 sec(s) Train Acc: 0.962183 Loss: 0.001858 | Val Acc: 0.969400 loss: 0.001423\n",
      "[002/030] 15.18 sec(s) Train Acc: 0.973250 Loss: 0.001290 | Val Acc: 0.983600 loss: 0.000740\n",
      "[003/030] 17.97 sec(s) Train Acc: 0.978767 Loss: 0.001059 | Val Acc: 0.988100 loss: 0.000551\n",
      "[004/030] 18.44 sec(s) Train Acc: 0.980717 Loss: 0.000947 | Val Acc: 0.987800 loss: 0.000591\n",
      "[005/030] 18.27 sec(s) Train Acc: 0.983133 Loss: 0.000816 | Val Acc: 0.982800 loss: 0.000839\n",
      "[006/030] 16.99 sec(s) Train Acc: 0.984167 Loss: 0.000749 | Val Acc: 0.983900 loss: 0.000789\n",
      "[007/030] 15.35 sec(s) Train Acc: 0.986200 Loss: 0.000671 | Val Acc: 0.988600 loss: 0.000580\n",
      "[008/030] 15.34 sec(s) Train Acc: 0.986583 Loss: 0.000635 | Val Acc: 0.987600 loss: 0.000583\n",
      "[009/030] 15.50 sec(s) Train Acc: 0.987433 Loss: 0.000602 | Val Acc: 0.988200 loss: 0.000612\n",
      "[010/030] 15.88 sec(s) Train Acc: 0.988150 Loss: 0.000587 | Val Acc: 0.984600 loss: 0.000842\n",
      "[011/030] 14.99 sec(s) Train Acc: 0.988917 Loss: 0.000537 | Val Acc: 0.989600 loss: 0.000490\n",
      "[012/030] 15.67 sec(s) Train Acc: 0.989567 Loss: 0.000507 | Val Acc: 0.990300 loss: 0.000475\n",
      "[013/030] 15.83 sec(s) Train Acc: 0.989233 Loss: 0.000495 | Val Acc: 0.991200 loss: 0.000444\n",
      "[014/030] 14.78 sec(s) Train Acc: 0.990933 Loss: 0.000451 | Val Acc: 0.990400 loss: 0.000506\n",
      "[015/030] 15.09 sec(s) Train Acc: 0.990750 Loss: 0.000431 | Val Acc: 0.989500 loss: 0.000515\n",
      "[016/030] 14.01 sec(s) Train Acc: 0.991350 Loss: 0.000411 | Val Acc: 0.991900 loss: 0.000426\n",
      "[017/030] 16.82 sec(s) Train Acc: 0.991600 Loss: 0.000408 | Val Acc: 0.991300 loss: 0.000451\n",
      "[018/030] 18.04 sec(s) Train Acc: 0.992300 Loss: 0.000375 | Val Acc: 0.989300 loss: 0.000551\n",
      "[019/030] 16.60 sec(s) Train Acc: 0.992500 Loss: 0.000376 | Val Acc: 0.989100 loss: 0.000578\n",
      "[020/030] 15.62 sec(s) Train Acc: 0.992367 Loss: 0.000360 | Val Acc: 0.990600 loss: 0.000481\n",
      "[021/030] 15.10 sec(s) Train Acc: 0.992983 Loss: 0.000329 | Val Acc: 0.988800 loss: 0.000619\n",
      "[022/030] 15.83 sec(s) Train Acc: 0.993500 Loss: 0.000316 | Val Acc: 0.992200 loss: 0.000428\n",
      "[023/030] 16.27 sec(s) Train Acc: 0.993433 Loss: 0.000306 | Val Acc: 0.989300 loss: 0.000609\n",
      "[024/030] 16.61 sec(s) Train Acc: 0.993000 Loss: 0.000323 | Val Acc: 0.991400 loss: 0.000444\n",
      "[025/030] 17.69 sec(s) Train Acc: 0.993683 Loss: 0.000288 | Val Acc: 0.988300 loss: 0.000644\n",
      "[026/030] 18.27 sec(s) Train Acc: 0.994167 Loss: 0.000273 | Val Acc: 0.990500 loss: 0.000493\n",
      "[027/030] 14.69 sec(s) Train Acc: 0.994483 Loss: 0.000266 | Val Acc: 0.990700 loss: 0.000526\n",
      "[028/030] 13.52 sec(s) Train Acc: 0.994200 Loss: 0.000263 | Val Acc: 0.988200 loss: 0.000660\n",
      "[029/030] 16.08 sec(s) Train Acc: 0.994333 Loss: 0.000261 | Val Acc: 0.991300 loss: 0.000497\n",
      "[030/030] 14.78 sec(s) Train Acc: 0.994783 Loss: 0.000251 | Val Acc: 0.990800 loss: 0.000492\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "for epoch in range(epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    train_acc =0.0\n",
    "    val_acc =0.0\n",
    "    train_loss = 0.0\n",
    "    val_loss =0.0\n",
    "    model.train()\n",
    "    for i,data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x,y = data[0].to(device),data[1].to(device)\n",
    "        #print(x.shape)\n",
    "        y_pred = model(x)\n",
    "        loss = cirection(y_pred,y.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_acc +=np.sum(np.argmax(y_pred.cpu().data.numpy(),axis=1)== y.cpu().numpy())\n",
    "        train_loss +=loss.item()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(val_loader):\n",
    "            valx ,valy = data[0].to(device),data[1].to(device)\n",
    "            val_pred = model(valx)\n",
    "            batch_loss = cirection(val_pred,valy.long())\n",
    "            val_acc +=np.sum(np.argmax(val_pred.cpu().data.numpy(),axis=1)== valy.cpu().numpy())\n",
    "            val_loss +=batch_loss.item()\n",
    "\n",
    "        print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\n",
    "            (epoch + 1, epochs, time.time()-epoch_start_time, \\\n",
    "             train_acc/train_set.__len__(), train_loss/train_set.__len__(), val_acc/val_set.__len__(), val_loss/val_set.__len__()))\n",
    "    model.train()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0843aa2147bb7b68e1331c060614b1ebfeaba0f0db744f4b489daeb337a1f0b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
