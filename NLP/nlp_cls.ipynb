{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP 数据处理+ 分类\n",
    "### 采用了fake news dataset <https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset>\n",
    "### 使用pyTorch 框架或TF 主要学习数据处理，怎么处理文本到向量的转变\n",
    "### 部分代码参考 <https://www.kaggle.com/rushinaik/mission-torch-1#Train-Test-Splitting>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "#TfidVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import scipy\n",
    "from torch import optim\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  label  \n",
       "0  December 31, 2017       1  \n",
       "1  December 29, 2017       1  \n",
       "2  December 31, 2017       1  \n",
       "3  December 30, 2017       1  \n",
       "4  December 29, 2017       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#overview the data\n",
    "df1 = pd.read_csv('D:/ML_data_sql/news/True.csv')\n",
    "df2 = pd.read_csv('D:/ML_data_sql/news/Fake.csv')\n",
    "df1['label'] = 1\n",
    "df2['label'] = 0\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "\n",
    "del df1 \n",
    "del df2\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (44898, 5)\n",
      "\n",
      "Sum of nulls:\n",
      "title      0\n",
      "text       0\n",
      "subject    0\n",
      "date       0\n",
      "label      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of the dataset: {df.shape}')\n",
    "print(f'\\nSum of nulls:\\n{df.isna().sum()}')\n",
    "#发现没有空的 空的可能要补上之类的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 44898 entries, 0 to 23480\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    44898 non-null  object\n",
      " 1   text     44898 non-null  object\n",
      " 2   subject  44898 non-null  object\n",
      " 3   date     44898 non-null  object\n",
      " 4   label    44898 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing \n",
    "def normalise_text(text):\n",
    "    #re  to normalise\n",
    "    text = text.str.lower()\n",
    "    text = text.str.replace(r\"\\#\",'')\n",
    "    text = text.str.replace(r'http\\S+','URL')\n",
    "    text = text.str.replace(r'@','')\n",
    "    text = text.str.replace(r\"[^A-Za-z0-9()!?\\'\\`\\\"]\",' ')\n",
    "    text = text.str.replace(\"\\s{2,}\",\" \")\n",
    "\n",
    "    return text\n",
    "\n",
    "df['text'] = df['title'] +\" \"+df['text']\n",
    "df['text'] = normalise_text(df['text'])\n",
    "del df['title']\n",
    "del df['subject']\n",
    "del df['date']\n",
    "#split train and test\n",
    "#7:3\n",
    "#word -> vector  simple\n",
    "X_train,X_test,y_train,y_test = train_test_split(df['text'],df['label'],test_size=0.3)\n",
    "#create vector \n",
    "vectorize = TfidfVectorizer(ngram_range=(1,1),max_features=10000)\n",
    "\n",
    "X_train = vectorize.fit_transform(X_train)\n",
    "X_test = vectorize.fit_transform(X_test)\n",
    " \n",
    "#稠密矩阵\n",
    "X_train = torch.tensor(X_train.todense()).float() \n",
    "X_test = torch.Tensor(X_test.todense()).float()\n",
    "y_train = torch.tensor(y_train.values)\n",
    "y_test = torch.tensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100..  Training Loss: 0.488..  Test Loss: 0.665..  Test Accuracy: 0.565\n",
      "Epoch: 20/100..  Training Loss: 0.248..  Test Loss: 0.651..  Test Accuracy: 0.594\n",
      "Epoch: 30/100..  Training Loss: 0.137..  Test Loss: 0.714..  Test Accuracy: 0.592\n",
      "Epoch: 40/100..  Training Loss: 0.085..  Test Loss: 0.808..  Test Accuracy: 0.593\n",
      "Epoch: 50/100..  Training Loss: 0.058..  Test Loss: 0.890..  Test Accuracy: 0.593\n",
      "Epoch: 60/100..  Training Loss: 0.042..  Test Loss: 0.950..  Test Accuracy: 0.597\n",
      "Epoch: 70/100..  Training Loss: 0.032..  Test Loss: 0.993..  Test Accuracy: 0.602\n",
      "Epoch: 80/100..  Training Loss: 0.025..  Test Loss: 1.020..  Test Accuracy: 0.607\n",
      "Epoch: 90/100..  Training Loss: 0.019..  Test Loss: 1.041..  Test Accuracy: 0.612\n",
      "Epoch: 100/100..  Training Loss: 0.016..  Test Loss: 1.061..  Test Accuracy: 0.616\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# model = nn.Sequential(\n",
    "#                 nn.Linear(X_train.shape[1],128 ),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Dropout(0.1),\n",
    "#                 nn.Linear(128, df['label'].nunique()),\n",
    "#                 nn.LogSoftmax(dim=1)\n",
    "# )\n",
    "# # defining the loss \n",
    "# criterion = nn.NLLLoss()\n",
    "\n",
    "# # Forward pass, get our logits\n",
    "# logps = model(X_train)\n",
    "\n",
    "# # Calculate the loss with the logits and the labels\n",
    "# loss = criterion(logps, y_train)\n",
    "\n",
    "\n",
    "# loss.backward()\n",
    "\n",
    "# # Optimizers require the parameters to optimize and a learning rate\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
    "\n",
    "# train_losses = []\n",
    "# test_losses = []\n",
    "# test_accuracies = []\n",
    "\n",
    "# epochs = 100\n",
    "# for e in range(epochs):\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     output = model.forward(X_train)\n",
    "#     loss = criterion(output, y_train)\n",
    "#     loss.backward()\n",
    "#     train_loss = loss.item()\n",
    "#     train_losses.append(train_loss)\n",
    "    \n",
    "#     optimizer.step()\n",
    "    \n",
    "    \n",
    "#     # Turn off gradients for validation, saves memory and computations\n",
    "#     with torch.no_grad():\n",
    "#         model.eval()\n",
    "#         log_ps = model(X_test)\n",
    "#         test_loss = criterion(log_ps, y_test)\n",
    "#         test_losses.append(test_loss)\n",
    "\n",
    "#         ps = torch.exp(log_ps)\n",
    "#         top_p, top_class = ps.topk(1, dim=1)\n",
    "#         equals = top_class == y_test.view(*top_class.shape)\n",
    "#         test_accuracy = torch.mean(equals.float())\n",
    "#         test_accuracies.append(test_accuracy)\n",
    "\n",
    "#     model.train()\n",
    "#     if (e+1)%10==0:\n",
    "#         print(f\"Epoch: {e+1}/{epochs}.. \",\n",
    "#               f\"Training Loss: {train_loss:.3f}.. \",\n",
    "#               f\"Test Loss: {test_loss:.3f}.. \",\n",
    "#               f\"Test Accuracy: {test_accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/100] 11.79 sec(s) Train Acc: 0.922362 Loss: 0.000197 | Val Acc: 0.570007 loss: 0.002464\n",
      "[011/100] 11.72 sec(s) Train Acc: 1.000000 Loss: 0.000000 | Val Acc: 0.621752 loss: 0.004961\n",
      "[021/100] 13.31 sec(s) Train Acc: 1.000000 Loss: 0.000000 | Val Acc: 0.621678 loss: 0.005959\n",
      "[031/100] 13.27 sec(s) Train Acc: 1.000000 Loss: 0.000000 | Val Acc: 0.621752 loss: 0.006183\n",
      "[041/100] 12.39 sec(s) Train Acc: 1.000000 Loss: 0.000000 | Val Acc: 0.621158 loss: 0.006336\n",
      "[051/100] 12.53 sec(s) Train Acc: 1.000000 Loss: 0.000000 | Val Acc: 0.621158 loss: 0.006448\n",
      "[061/100] 13.69 sec(s) Train Acc: 1.000000 Loss: 0.000000 | Val Acc: 0.621158 loss: 0.006544\n",
      "[071/100] 13.47 sec(s) Train Acc: 1.000000 Loss: 0.000000 | Val Acc: 0.621158 loss: 0.006629\n",
      "[081/100] 12.93 sec(s) Train Acc: 1.000000 Loss: 0.000000 | Val Acc: 0.621158 loss: 0.006707\n",
      "[091/100] 13.79 sec(s) Train Acc: 1.000000 Loss: 0.000000 | Val Acc: 0.621232 loss: 0.006778\n",
      "Wall time: 21min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#train acc = 1  test acc = 0.62\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "class NLPDataset(Dataset):\n",
    "    def __init__(self, x, y=None):\n",
    "        self.x = x\n",
    "        # label is required to be a LongTensor\n",
    "        self.y = y\n",
    "        if y is not None:\n",
    "            self.y = torch.LongTensor(y)\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, index):\n",
    "        X = self.x[index]\n",
    "        if self.y is not None:\n",
    "            Y = self.y[index]\n",
    "            return X, Y\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "batch_size= 1024\n",
    "train_set = NLPDataset(X_train,y_train)\n",
    "test_set = NLPDataset(X_test,y_test)\n",
    "train_loader = DataLoader(train_set,batch_size = batch_size,shuffle=True)\n",
    "test_loader = DataLoader(test_set,batch_size=batch_size,shuffle=False)\n",
    "#model \n",
    "import torch.nn.functional as F\n",
    "class LR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LR,self).__init__()\n",
    "        #tensor 50* 50*1\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(10000, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(128,2)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        out = self.fc(x)\n",
    "        #out = F.softmax(out,dim=1)\n",
    "        return out \n",
    "\n",
    "#settings \n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "model = LR().to(device)\n",
    "cirection = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr =0.002)\n",
    "import time\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    train_acc =0.0\n",
    "    val_acc =0.0\n",
    "    train_loss = 0.0\n",
    "    val_loss =0.0\n",
    "    model.train()\n",
    "    for i,data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x,y = data[0].to(device),data[1].to(device)\n",
    "        # print(x.shape)\n",
    "        y_pred = model(x)\n",
    "        loss = cirection(y_pred,y.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_acc +=np.sum(np.argmax(y_pred.cpu().data.numpy(),axis=1)== y.cpu().numpy())\n",
    "        train_loss +=loss.item()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(test_loader):\n",
    "            valx ,valy = data[0].to(device),data[1].to(device)\n",
    "            val_pred = model(valx)\n",
    "            batch_loss = cirection(val_pred,valy.long())\n",
    "            val_acc +=np.sum(np.argmax(val_pred.cpu().data.numpy(),axis=1)== valy.cpu().numpy())\n",
    "            val_loss +=batch_loss.item()\n",
    "    if epoch %10==0: \n",
    "        print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\n",
    "            (epoch + 1, epochs, time.time()-epoch_start_time, \\\n",
    "                train_acc/train_set.__len__(), train_loss/train_set.__len__(), val_acc/test_set.__len__(), val_loss/test_set.__len__()))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0843aa2147bb7b68e1331c060614b1ebfeaba0f0db744f4b489daeb337a1f0b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
